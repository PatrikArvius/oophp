---
---
Redovisning kmom03
=========================

**Har du tidigare erfarenheter av att skriva kod som testar annan kod?**

Ja det har jag, från kursen i objektorienterad python. Det känns dessutom förhållandevis bekant då det mer eller mindre fungerar på exakt samma sätt bortsätt från användningen av namespace vilket i php innebär att jag inte behöver börja mina test genom att importera de klasser jag avser att testa. Testningen i sig ter sig på ett liknande sätt där vi extendar eller ärver från en testcase klass. Koncept som "setup" och "teardown" återfinns även i de båda språken och fungerar på ett liknande sätt. Med det sagt så är det ändå en hel del nya saker för mig i denna kursens tester som att skriva testbar kod, att skriva tester innan man skriver koden och användningen av verktyg som Xdebugger och code coverage som jag måste säga är ett väldigt trevligt verktyg. Jag uppskattar verkligen den översikt man får genom att generera code coverage och den enkelhet med vilken man kan överblicka den kod man testar samt vilka rader som man lyckas täcka med sina tester.

**Hur ser du på begreppen enhetstestning och “att skriva testbar kod”?**

Jag ser på dem som en mer eller mindre nödvändighet. I början när jag var helt ny till denna värld av programmering så var det jag skrev så litet att jag mer eller mindre manuellt kunde försäkra mig om att saker och ting fungerade som de skulle och det var också lite så som jag testade och felsökte, dvs. manuellt genom att köra mitt program eller att använda min sida. I takt med att jag fick mer erfarenhet och att programmen/projekten växte så blev det samtidigt mindre och mindre hållbart att sitta och manuellt undersöka att det jag gjorde fungerade. Inte bara så nådde komplexiteten en nivå där jag inte längre kunde se att jag testade det jag ville testa utan varje gång jag la till något så var jag tvungen att testa allt igen så att inget gick sönder eller började agera på ett oönskat sätt. Det var ungefär här som jag blev introducerad till enhetstester och att skriva tester för min kod. Detta i sin tur innebar en ökad möjlighet till att kunna överblicka min kod och att säkerställa att jag testade det jag var ute efter att testa. Dessutom innebär det en tidsbesparing redan andra gången vi behöver testa vår kodbas då testen redan finns skrivna och enkelt kan köras istället för att gå igenom samma tidskrävande manuella testande (som dessutom inte nödvändigtvis sker på samma sätt då jag måste komma ihåg själv exakt hur jag gjorde för att testa sakerna manuellt). På det viset ger enhetstester oss en ökad träffsäkerhet, en tidsbesparing i längden och en form utav säkerhet att vi alltid gör samma tester.

I takt med att erfarenhet kring enhetstestning ansamlades växte också ett frö kring att skriva testbar kod, förvisso inte till den grad likt det som togs upp på föreläsningen om att skriva tester först. Detta frö växte med de erfarenheter jag samlade på mig genom att först skriva min kod och sedan testa den vilket i många fall kom att innebära en hel del frustration när den kod jag ville testa inte riktigt gick att testa som jag ville. Detta i sin tur ledde till att jag när jag programmerade till större del hade testbarhet med mig i bakhuvudet och jag började skriva mer och mer generell kod som till större del enbart gjorde en sak. Det var sedan tidgare något som jag lärt mig var en god idé genom att slita mig i håret när jag försökte felsöka några groteska monsterfunktioner som gjorde tusen och en saker och enhetstester skapade än större förståelse för fördelarna med liten, generell och enkel kod som gjorde en sak.

Jag är dock ännu inte i den fas där jag skriver testerna först även om jag varvar skapandet av klasser och metoder med att skriva testfall för desamma. Men det är ett arbetssätt som jag har börjat uppskatta där jag skriver kod som jag sedan direkt kan skriva tester till för att försäkra mig om att den fungerar som jag tänkt mig att den skall fungera. Förvisso ställer detta i sin tur krav på att testerna i sig är utformade på ett så bra sätt att de testar koden uttömmande. Och jag har ännu mycket att lära, som hur jag använder mig utav "mocking" för att testa min kod. Jag hade några fall i detta kursmoment när jag kände att jag egentligen hade ett behov av att använda mig utav det för att testa på ett uttömande sätt, framför allt när det kom till att testa de delar i min kod där värden randomiserades vilket blir väldigt svårt att testa. Jag löste det genom att programmera in sätt att begränsa hur randomiseringen sköttes så att jag kunde sätta på scenarion där randomiseringen skedde inom ett specificerat område varpå jag kunde testa att det verkligen hamnade inom det avsedda området men jag är samtidigt medveten om att detta inte är ett optimalt förfarande. Det är något jag kommer lära mig mer om med tiden och någonstans måste man ändå dra ett streck för hur mycket tid man spenderar på ett kmom.

**Förklara kort begreppen white/grey/black box testing samt positiva och negativa tester, med dina egna ord.**

White box testing är likt det vi hållit på med i detta kmom tester där vi kan se allt, där vi kan se varje individuell kodrad och hur och om den har blivit testad eller ej. Likt hur code coverage visar oss grafiskt vilka rader i vår kod som vi testat eller ej. Black box testing är till skillnad från white box testing mer av en funktionell natur där du inte kan se och egentligen inte riktigt bryr dig om hur varje enskild kodrad fungerar, jag ser det lite som att du står vid en startpunkt utanför den svarta lådan av magi (koden) och du vet vad du förväntar dig för resultat när du passerat genom koden, om resultatet är vad du förväntat dig så är du nöjd. Det skulle t.ex. kunna vara att du vill logga in på en sida med en viss användare, du förväntar dig att detta skall fungera och att du blir inloggad med rätt användare, om så är fallet är du nöjd. Min förståelse av grey box testing är att det är en blanding av de två tidigare nämnda sätten vilket namnet också anspelar på, det innebär ett liknande förfarande som i black box testing fast med en kunskap om den bakomliggande koden som är närmre white box testing. Du har mer koll på hur saker och ting fungerar eller ska fungera under ytan och kan på så vis testa saker på ett mer målinriktat sätt även om det inte är lika minutiöst som i white box testing.

**Berätta om hur du löste uppgiften med Tärningsspelet 100, hur du tänkte, planerade och utförde uppgiften samt hur du organiserade din kod?**

Först och främst tänkte jag att jag troligtvis kunde återanvända kod som jag skrivit tidigare i form utav mina klasser för en tärning och en tärningshand. Det visade sig att jag kunde gör det också till stor utsträckning. Utöver det så tänkte jag mig ändå att jag på något vis ville skapa så generella klasser som möjligt, det kan till viss del ha inneburit att jag har en lite lång kompositionskedja av klasser vars instanser skapas inom ramen av varandra men jag tänkte ändå att jag ville ha klasser som kan göra saker som känns rimliga för respektive klass att göra. Jag hade säkert kunnat lösa uppgiften bara genom att använda mig av tärningshänder och deras tärningar men jag tyckte att jag ville göra det lite mer övergripande.

Inledningsvis skissade jag upp ett UML-diagram med papper och penna över vilka klasser jag ville ha och vad jag ville att de skulle kunna göra sedan påbörjades en itterativ process där jag började koda mina klasser, skriva tester, ändra i mina klasser och skriva mer tester om vart annat tills dess att uppgiften var avklarad mer eller mindre. Därefter gjorde jag ett snyggare UML-diagram med draw.io som ersatte mitt mina skisser, ett UML-diagram som kanske kom lite sent i projektet om vi skall mäta dess planeringsvärde vilket snarare kom från mitt kladdpapper. 

Jag har tidigare inte använt mig särskillt mycket utav arv då jag kunnat lösa det mesta med ren aggregation eller komposition och individuella klasser men jag var ganska tidigt inne på att jag ville ha klasser för både en spelare och en motståndare i form utav "datorn". Detta i sin tur väckte en tanke om att det ända som skiljer sig mellan en spelare och en dator är egentligen att spelaren själv väljer hur den hanterar resultatet av ett kast med tärningarna medan datorn behöver ha någon form utav automatiserat förfarande. Med det i åtanke tänkte jag att de mer eller mindre är samma klass förutom att de hanterar metoden "playRound()" olika varpå arv kändes som en bra idé där alla annan funktionalitet är densamma förutom att datorn ärver från spelaren och gör en overload på just den metoden och implementerar den på ett annat sätt. Datorns metod blev dessutom till viss del rekursiv i den mån att den spelar en ny runda om snittvärdet av ett kast är under en viss nivå. Jag hade förvisso kunnat ha samma klass för båda spelarna och skrivit två olika metoder i klassen där spelaren använde en metod och datorn den andra men det kändes mer intuitivt för mig att istället ärva och ändra funktionaliteten. Om inte annat så var det något jag lärde mig mycket av då jag inte arbetat så mycket med arv tidigare och det lärde mig mer om hur public, private och protected fungerade då jag till en början hade problem med att testa min dator-klass då jag inte hade satt attributen i min spalre-klass till protected utan private vilket efter mycket felsökande resulterade i att polletten föll ned.

I övrigt organiserade jag min kod som sådan att varje klass utförde vad man kunde förvänta sig att en sådan klass bör utföra, som att en spelare spelar en runda och att en hand med tärningar som tillhör en spelare är den som kastar tärningarna när en runa spelas. Jag försökte även i större mån än tidigare skriva så testbar kod som möjligt och det addition av vissa ytterligare metoder i form utav setters och getters samt vissa extra parametrar och default värden i klassernas konstruktorer så att jag i större grad kunde manipulera hur klasserna skapades för att kunna säkerställa att de gjorde vad de skulle. Den största utmaningen var att testa allt som innebar randomisering och mina brister i de fallen har jag nämnt tidigare, utöver det så har jag lite svårt att veta hur jag ska använda mig av mina klasser utanför dom i själva integrationen med routes och ramverket. Hur mycket ska jag hantera i routen, hur mycket ska jag hantera i min "play-sida" och hur mycket ska jag hantera i post-processing. Jag fick det hela att fungera som tänkt och bra är väl det men det var något som hela tiden låg i mitt bakhuvud.

**Hur väl lyckades du testa tärningsspelet 100?**

Jag tycker jag lyckades ganska bra med att testa spelet, jag försökte verkligen anamma tänkesättet kring att skriva testbar kod och jag arbetade med kod och tester om vartannat. Jag lyckades nästa testa varenda rad även om vissa brister finns i min testning av randomiserade aspekter vilket egentligen nog krävt en del mocking men som jag löste genom att istället manipulera gränserna för randomiseringen som att ändra vilket värde som är en tärnings minsta värde samt hur många sidor en tärning har. Detta lät mig skriva test där en tärning t.ex. inte ens kunde rulla en etta eftersom jag skapat en tärning med minsta värdet två. Eller ett test med en tärning som bara har en sida och sålledes bara kan rulla en etta för att testa att rätt sak händer när en etta rullas. Den kodrad jag inte kom åt var i min computer-klass där en del av "playRound()"-metoden var rekursiv, jag kunde manipulera in-värdet till den grad att jag nådde den rekursiva delen men eftersom in-värdet är detsamma jämfört med i det verkliga spelet så skapas en oändlighetsloop. Det finns säkert en trevlig lösning för detta men jag hade inte riktigt tid att förkovra mig i det.

**Vilken är din TIL för detta kmom?**

Att enhetstestning och code coverage är ett väldigt trevliga verktyg och att de verkligen underlättar överblicken av koden. Just att se visuellt hur mycket av min kod som jag testat var väldigt intressant även om det till viss del lurar in en att vilja testa 100% vilket i vissa fall kanske kräver lite mer tid än vad man har till hands. Lite som Mikael sa på sin föreläsning om förtida optimisering, någonstans finns det en gräns för hur mycket finslipande som är rimligt att göra.